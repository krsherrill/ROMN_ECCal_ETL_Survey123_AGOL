{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea85543",
   "metadata": {},
   "source": [
    "<h1>Script to Extract Transform and Load Error Check Calibration Survey 123 data on AGOL to the ROMN Water Quality Database</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23cf6a",
   "metadata": {},
   "source": [
    "<h3>Code Processes the ROMN Error Check Calibration Data collected in Survey 123 from the defined Feature Layer on ArcGIS Online to the defined Water Quality Access Database:<br><br>\n",
    "    1)Downloads via the ArcGIS Python API the Error Check Calibration Feature Layer (i.e. Survey 123 EC/Cal data/table) <br><br>\n",
    "    2)Preprocessed fields in the Feature Layer to Match the expected schema in the 'tbl_Form0_WQ_EC_Cal_Master' table<br><br>\n",
    "    3)Appends records to the 'tbl_Form0_WQ_EC_Cal_Master' table in the defined Water Quality Access Database</h3><br>\n",
    "         \n",
    "<h5>Dependicies:<br>\n",
    "Python Version 3.8<br>\n",
    "Packages: Pandas, Numpy, shutil, sys, os<br>\n",
    "Anaconda Environment: py38<br>\n",
    "sqlalchemyh-access - used for pandas dataframe '.to_sql' functionality: install via: 'pip install sqlalchemy-access'<br><br>\n",
    "An ArcGIS Online Application Client Id must be created in order to connect with AGOL via the python API.  This application client it must be OAuth 2.0 registered and allows for two factor identification.\n",
    " \n",
    "\n",
    "\n",
    "<h5>Notebook created by Kirk Sherrill - Data Manager Rock Mountian Network - I&M National Park Service<br>\n",
    "    Date - May 26th, 2022</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import date\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import traceback\n",
    "\n",
    "#import pyodbc - not being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a76a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7caa06",
   "metadata": {},
   "source": [
    "<h3>Define Input Parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75accc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Cell Width to be Dynamic\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fefc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Number of maximum row to display to 1000\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGOL_ID = 'fad0563cc2a4401ba94a6131a7dc5a31'  #The Service ItemID (i.e. the AGOL Identification number) for the Error Check Calibration Survey 123 Feature Layer.\n",
    "\n",
    "pythonApp_ID = 'VFfN107sG4W47jXo'  #AGOL Application Client Id. In order to download from AGOL the python application must be OAuth 2.0 registered.\n",
    "downloadFormat = 'CSV'  #Desired format of downloaded Feature ('CSV'|'Excel')\n",
    "\n",
    "#Water Quality Access Database\n",
    "WQDB = r'C:\\ROMN\\Monitoring\\Loggers\\Data\\Certified\\WaterQuality_ROMN_AllYears_MASTER_20221026v5.accdb'    #ROMN Water Quality Access DB - where the 'tbl_Form0_WQ_EC_Cal_Master' table to be append to.\n",
    "WQDBTable = 'tbl_Form0_WQ_EC_Cal_Master'   #Table in 'WQDB' to be appended to (i.e. 'tbl_Form0_WQ_EC_Cal_Master')\n",
    "\n",
    "#Output Name and Directory Paths\n",
    "outZipName = \"EC_Cal_Survey123_2022\"    #Name given to zip file during export from AGOL\n",
    "outRawTable = \"Form0_0\"     #Name of layer being exported from AGOL\n",
    "workspace = r'C:\\ROMN\\Monitoring\\Loggers\\DataGathering\\WaterQuality\\EC_Cal_Survey123\\2022\\2022_Download_AGOL_EC_Cal'  #Workspace Output Directory\n",
    "logFileName = workspace + \"\\\\\" + outZipName + \".LogFile.txt\"  #Name of the .txt script logfile which is saved in the workspace directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43398363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Checking for working directories and Log File\n",
    "##################################\n",
    "if os.path.exists(workspace):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(workspace)\n",
    "\n",
    "# Check if logFile exists\n",
    "if os.path.exists(logFileName):\n",
    "    pass\n",
    "else:\n",
    "    logFile = open(logFileName, \"w\")  # Creating index file if it doesn't exist\n",
    "    logFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b444e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Get the Date/Time\n",
    "def timeFun():\n",
    "    from datetime import datetime\n",
    "    b=datetime.now()\n",
    "    messageTime = b.isoformat()\n",
    "    return messageTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c156d7",
   "metadata": {},
   "source": [
    "<h3>Download AGOL Feature Layer/Survey 123 table via ArcGIS.API</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe79f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gis = GIS(None,verify_cert=True)\n",
    "#gis = GIS('https://nps.maps.arcgis.com',verify_cert=False)\n",
    "#gis = GIS('https://nps.maps.arcgis.com',\"NPS\\\\ksherrill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90273728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Connection to AGOL via the ArcGIS API - ArcGIS.GIS module, using a Python application client_id connection for authentication\n",
    "gis = GIS('https://nps.maps.arcgis.com',client_id='VFfN107sG4W47jXo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46341cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get List of AGOL Content by owner or Directly define the AGOL Item ID\n",
    "#owner = 'ksherrill@nps.gov_nps'\n",
    "##owner ='kzybko@nps.gov_nps'\n",
    "#items = gis.content.search('owner:{0}'.format(owner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e333935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the desired AGOL content via the AGOL ID\n",
    "item=gis.content.get(AGOL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ed70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the imported AGOL content\n",
    "#result = item.export(item.title, downloadFormat, wait=True)\n",
    "result = item.export(outZipName, downloadFormat, wait=True)\n",
    "result.download(workspace)\n",
    "\n",
    "zipFull = workspace + \"\\\\\" + outZipName + \".zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "messageTime = timeFun()\n",
    "scriptMsg = \"Successfully Exported Item: \" + AGOL_ID + \" from AGOL to: \" + zipFull + \" - \" + messageTime\n",
    "print(scriptMsg)\n",
    "logFile = open(logFileName, \"a\")\n",
    "logFile.write(scriptMsg + \"\\n\")\n",
    "logFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02706cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip and export to the workspace\n",
    "with ZipFile(zipFull, 'r') as zip:\n",
    "    print ('Unzipping files')\n",
    "    zip.extractall(path=workspace)\n",
    "\n",
    "outFullTable = workspace + \"\\\\\" + outRawTable + \".\" + downloadFormat   \n",
    "messageTime = timeFun()\n",
    "scriptMsg = \"Successfully Unzipped: \" + outZipName + \".zip to: \" + outFullTable\n",
    "print(scriptMsg)\n",
    "logFile = open(logFileName, \"a\")\n",
    "logFile.write(scriptMsg + \"\\n\")\n",
    "logFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842d145",
   "metadata": {},
   "source": [
    "<h3>Begin Processing to Upload the AGOL export to Access Database</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f53466",
   "metadata": {},
   "outputs": [],
   "source": [
    "outFullTable = workspace + \"\\\\\" + outRawTable + \".\" + downloadFormat   \n",
    "#Import excel or csv file to Pandas Dataframe\n",
    "if downloadFormat.lower() == \"csv\":\n",
    "    df = pd.read_csv(outFullTable)\n",
    "else:\n",
    "    df = pd.read_excel(outFullTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 'DeviceSN' field\n",
    "df.insert(9,\"DeviceSN\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9dd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining SN fields to Integer then to String\n",
    "df['SmarTroll_SN'] = df['SmarTroll_SN'].fillna(0).astype(int)\n",
    "df['SmarTroll_SN'] = df['SmarTroll_SN'].astype('str')\n",
    "df['AquaTroll600_SN'] = df['AquaTroll600_SN'].fillna(0).astype(int)\n",
    "df['AquaTroll600_SN'] = df['AquaTroll600_SN'].astype('str')\n",
    "df['Aquatroll400_SN'] = df['Aquatroll400_SN'].fillna(0).astype(int)\n",
    "df['Aquatroll400_SN'] = df['Aquatroll400_SN'].astype('str')\n",
    "df['Oakton_SN'] = df['Oakton_SN'].fillna(0).astype(int)\n",
    "df['Oakton_SN'] = df['Oakton_SN'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15588c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Processing being done with function 'processDeviceSerialNumber'\n",
    "# df['DeviceSN'] = np.where((df['Sonde'] == 'smartroll'), df['SmarTroll_SN'], df['DeviceSN'])\n",
    "# df['DeviceSN'] = np.where((df['Sonde'] == 'aquatroll_600'), df['AquaTroll600_SN'], df['DeviceSN'])\n",
    "# df['DeviceSN'] = np.where((df['Sonde'] == 'aquatroll_400'), df['Aquatroll400_SN'], df['DeviceSN'])\n",
    "# # df['DeviceSN'] = np.where((df['Sonde'] == 'oakton_pc_450'), df['Oakton_SN'], df['DeviceSN'])\n",
    "# df['DeviceSN'] = np.where((df['Sonde'] == 'other'), df['Other_Sonde_Type_Serial'], df['DeviceSN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac29201",
   "metadata": {},
   "source": [
    "<h3>Replace 'Other' Values in Crew and SiteName fields with mathcing 'Other' fields</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to work through the Defined Fields checking for 'other' values in the 'inField' if there is an 'other' value populate with the defiend ifOtherField.<br>\n",
    "#Input Parameters:\n",
    "#'inDf' - data frame being evaluated\n",
    "#'inField' - field being checked if 'Other' value \n",
    "#'ifOtherField - field to populate 'inField' when 'inField' is 'other'\n",
    "\n",
    "def replaceOtherField(inDf, inField, ifOtherField):\n",
    "    try:\n",
    "             \n",
    "        inDf[inField] = np.where((inDf[inField] == 'other'), inDf[ifOtherField], df[inField])\n",
    "        \n",
    "        return \"Success Function\", inDf\n",
    "        \n",
    "    except:\n",
    "\n",
    "        messageTime = tim\n",
    "        eFun()\n",
    "        print(\"Error on 'replaceOtherField' Function \")\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return \"Failed function - 'replaceOtherField'\"    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4240820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function for 'Crew' field with 'Other' field\n",
    "outVal = replaceOtherField(df,\"Crew\", \"Specify other.\" )\n",
    "if outVal[0].lower() != \"success function\":\n",
    "    print (\"WARNING - Function 'replaceOtherField' - Failed for 'Crew' field - Exiting Script\")\n",
    "else:\n",
    "\n",
    "    print (\"Success - Function 'replaceOtherField - Crew'\")\n",
    "    #Assign the df to the processed df\n",
    "    df = outVal[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878875a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function for 'SiteName' field with 'Other' field\n",
    "outVal = replaceOtherField(df,\"SiteName\", \"Specify other..1\" )\n",
    "if outVal[0].lower() != \"success function\":\n",
    "    print (\"WARNING - Function 'replaceOtherField' - Failed for 'SiteName' field - Exiting Script\")\n",
    "else:\n",
    "\n",
    "    print (\"Success - Function 'replaceOtherField - SiteName'\")\n",
    "    #Assign the df to the processed df\n",
    "    df = outVal[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c5211",
   "metadata": {},
   "source": [
    "<h3>Process Device Series Number Fields</h3><br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6944785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Populate the 'DeviceSN' field<br>\n",
    "#Input Parameters:\n",
    "#'inDf' - data frame being evaluated\n",
    "\n",
    "######Function Not Being Used - KRS 20220525\n",
    "\n",
    "def processDeviceSerialNumber(inDf):\n",
    "    try:\n",
    "        \n",
    "        inDf['DeviceSN'] = np.where((inDf['Sonde'] == 'smartroll'), inDf['SmarTroll_SN'], inDf['DeviceSN'])\n",
    "        inDf['DeviceSN'] = np.where((inDf['Sonde'] == 'aquatroll_400'), inDf['Aquatroll400_SN'], inDf['DeviceSN'])\n",
    "        inDf['DeviceSN'] = np.where((inDf['Sonde'] == 'aquatroll_600'), inDf['AquaTroll600_SN'], inDf['DeviceSN'])\n",
    "        inDf['DeviceSN'] = np.where((inDf['Sonde'] == 'oakton_pc_450'), inDf['Oakton_SN'], inDf['DeviceSN'])\n",
    "        inDf['DeviceSN'] = np.where((inDf['Sonde'] == 'other'), inDf['Other_Sonde_Type_Serial'], inDf['DeviceSN'])\n",
    "        \n",
    "        return \"Success Function\", inDf\n",
    "        \n",
    "    except:\n",
    "\n",
    "        messageTime = timeFun()\n",
    "        print(\"Error on 'replaceNullOtherField' Function \")\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return \"Failed function - 'replaceNullOtherField'\"    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function for 'Crew' field with 'Other' field\n",
    "outVal = processDeviceSerialNumber(df)\n",
    "if outVal[0].lower() != \"success function\":\n",
    "    print (\"WARNING - Function 'processDeviceSerialNumber' - Failed - Exiting Script\")\n",
    "else:\n",
    "\n",
    "    print (\"Success - Function 'processDeviceSerialNumber'\")\n",
    "    #Assign the df to the processed df\n",
    "    df = outVal[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Fields Not in 'tbl_Form0_WQ_EC_Cal_Master'\n",
    "df.drop(['ObjectID','DateSimple','Specify other.','Specify other..1','SmarTroll_SN','AquaTroll600_SN','Aquatroll400_SN','Oakton_SN','Other_Sonde_Type_Serial'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7c5c8",
   "metadata": {},
   "source": [
    "<h3>Connect with the 'WQDB' to push the new Error Check/Calibration records</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa988e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the Master Water Quality Table via sqlAlchemy-access connection\n",
    "#connStr_pyodbc = (r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=\" + waterQualityDB  +\";\")   #PYODBC Connection\n",
    "connStr = (r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=\" + WQDB  +\";ExtendedAnsiSQL=1;\")  #sqlAlchemy-access connection\n",
    "#cnxn = pyodbc.connect(connStr)  #PYODBC Connection\n",
    "cnxn = sa.engine.URL.create(\"access+pyodbc\", query={\"odbc_connect\": connStr})\n",
    "engine = sa.create_engine(cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define New Index field order and create new dateframe\n",
    "newIndex = ['GlobalID','Protocol','SiteName','EventName_ECCal','Date','Type','Crew','Sonde','DeviceSN','Notes','Temp_Sensor_Check','Temp_EC1_C','Temp_Sonde1_C','Temp_EC2_C','Temp_sonde2_C','Temp_Mean_Difference','Temp_EC_CommentAction','pH_EC_PreCal_Temp','pH_EC_PreCal_Standard','pH_EC_PreCalibrated_Reading','pH_EC_PreCalibrated_dif_EC_Standard','pH_EC_PreCal_Allowable','pH_EC_PreCal_CommentAction','pH_Cal1_Temp','pH_Cal1_Standard','pH_Cal1_Reading','pH_Cal2_Temp','pH_Cal2_Standard','pH_Cal2_Reading','pH_Cal1_Cal2_CommentAction','pH_EC_PostCal_Temp','pH_EC_PostCal_Standard','pH_EC_PostCal_Reading','pH_EC_PostCal_dif_EC_Standard','pH_EC_PostCal_dif_EC_Standard_PercError','pH_EC_PostCal_Allowable','pH_EC_PostCal_CommentAction','SC_EC_PreCal_Temp','SC_EC_PreCal_Standard','SC_EC_PreCalibrated_Reading','SC_EC_PreCalibrated_dif_EC_Standard','SC_EC_PreCalibrated_dif_EC_PercError','SC_EC_PreCal_Allowable','SC_EC_PreCal_CommentAction','SC_Cal1_Temp','SC_Cal1_Standard','SC_Cal1_Reading','SC_Cal1_CommentAction','SC_EC_PostCal_Temp','SC_EC_PostCal_Standard','SC_EC_PostCal_Reading','SC_EC_PostCal_dif_EC_Standard','SC_EC_PostCal_dif_EC_Standard_PercError','SC_EC_PostCal_Allowable','SC_EC_PostCal_CommentAction','BP_mmHg','DO_EC_PreCal_Temp','DO_EC_PreCal_Standard','DO_EC_PreCal_Expected_mgl','DO_EC_PreCalibrated_Reading_mgl','DO_EC_PreCalibrated_Reading_perc','DO_EC_PreCalibrated_dif_EC_Standard','DO_EC_PreCal_dif_EC_Standard_PercError','DO_EC_PreCal_Allowable','DO_EC_PreCal_CommentAction','DO_1_or_2_pt_cal','DO_Cal1_Temp','DO_Cal1_Standard','DO_Cal1_Reading_mgl','DO_Cal1_Reading_perc','DO_Cal2_Temp','DO_Cal2_Standard','DO_Cal2_Reading_mgl','DO_Cal2_Reading_perc','DO_Cal1_Cal2_CommentAction','DO_EC_PostCal_Temp','DO_EC_PostCal_Standard','DO_EC_PostCal_Expected_mgl','DO_EC_PostCal_Reading_mgl','DO_EC_PostCal_Reading_perc','DO_EC_PostCal_dif_EC_Standard','DO_EC_PostCal_dif_EC_Standard_PercError','DO_EC_PostCal_Allowable','DO_EC_PostCal_CommentAction','Turb_EC_PreCal_Temp','Turb_EC_PreCal_Standard','Turb_EC_PreCalibrated_Reading','Turb_EC_PreCalibrated_dif_EC_Standard','Turb_EC_PreCalibrated_dif_EC_Standard_PercError','Turb_EC_PreCal_Allowable','Turb_EC_PreCal_CommentAction','Turb_Cal1_Temp','Turb_Cal1_Standard','Turb_Cal1_Reading','Turb_Cal2_Temp','Turb_Cal2_Standard','Turb_Cal2_Reading','Turb_Cal1_Cal2_CommentAction','Turb_EC_PostCal_Temp','Turb_EC_PostCal_Standard','Turb_EC_PostCal_Reading','Turb_EC_PostCal_dif_EC_Standard','Turb_EC_PostCal_dif_EC_Standard_PercError','Turb_EC_PostCal_Allowable','Turb_EC_PostCal_CommentAction','CreationDate','Creator','EditDate','Editor','x','y']\n",
    "\n",
    "#Apply new field index order to new dataframe\n",
    "df2 = df[newIndex]\n",
    "#df.reindex(newIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull from 'WQDBTable' table to get a count of existing records to be used to define the index\n",
    "query = \"SELECT \" + WQDBTable + \".* FROM \" + WQDBTable +\";\"\n",
    "query_Df = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of rows\n",
    "x=query_Df.shape\n",
    "lenRows = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the current maximum 'Form0_ID' value\n",
    "column = query_Df['Form0_ID']\n",
    "max_IdValue = column.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 'Form0_ID' field starting with incremental index starting at plus 1 the number of existing records in 'tbl_Form0_WQ_EC_Cal_Master'\n",
    "df2.insert(0,\"Form0_ID\",range(max_IdValue+1, max_IdValue + len(df2)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73227898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the dataframe index column and reassign to the 'Form0_ID' - necessary so you don't have an extra column\n",
    "df2.set_index('Form0_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create iteration range for records to be appended\n",
    "shapeDf =df2.shape\n",
    "lenRows = shapeDf[0]\n",
    "rowRange = range(0, lenRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append New records one at a time due to length constraints\n",
    "try:\n",
    "    for row in rowRange:\n",
    "\n",
    "        df3 = df2.iloc[row:row+1]\n",
    "        #Push to Series to get ID value\n",
    "        globalIDSeries = df3.iloc[0]\n",
    "        globalID = globalIDSeries.get('GlobalID') \n",
    "\n",
    "\n",
    "        #Append perfectly matching dataframe to WQDTable via pandas df.t.sql\n",
    "        x = df3.to_sql(WQDBTable, con=engine, if_exists='append')\n",
    "        #print(x)\n",
    "        messageTime = timeFun()        \n",
    "        scriptMsg = \"Successfully Appended 'GlobalID' - \" + globalID + \" - to DB: \" + WQDB + \" - \" + messageTime\n",
    "        print(scriptMsg)\n",
    "        logFile = open(logFileName, \"a\")\n",
    "        logFile.write(scriptMsg + \"\\n\")\n",
    "        logFile.close()\n",
    "\n",
    "        del(df3)\n",
    " \n",
    "    #Successfully Processed\n",
    "    messageTime = timeFun()        \n",
    "    scriptMsg = \"Successfully Processed Files in EC/Cal Feature Layer on AGOL with ID value:\" + AGOL_ID + \" - to DB: \" + WQDB + \" - \" + messageTime\n",
    "    print(scriptMsg)\n",
    "    logFile = open(logFileName, \"a\")\n",
    "    logFile.write(scriptMsg + \"\\n\")\n",
    "    logFile.close()\n",
    "   \n",
    "\n",
    "\n",
    "except:\n",
    "\n",
    "    messageTime = timeFun()\n",
    "    print(\"Error processing ErrorCheck_Cal_ETL_Survey123_AGOL.ipynb - \" + messageTime)\n",
    "    traceback.print_exc(file=sys.stdout)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del (engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45693e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "del (cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29bd41",
   "metadata": {},
   "source": [
    "<h3>Code Below Not Being Used</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300fff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to download AGOL data by user\n",
    "def downloadUserItems(owner, downloadFormat):\n",
    "    try:\n",
    "        # Search items by username\n",
    "        items = gis.content.search('owner:{0}'.format(owner))\n",
    "        print(items)\n",
    "        # Loop through each item and if equal to Feature service then download it\n",
    "        for item in items:\n",
    "            #if item.type == 'Feature Service':\n",
    "            if item.type == 'Feature Layer Collection':\n",
    "                result = item.export('sample {}'.format(item.title), downloadFormat)\n",
    "                result.download(workspace)\n",
    "                # Delete the item after it downloads to save on space\n",
    "                result.delete()\n",
    "            if item.type == 'Feature Service':\n",
    "                result = item.export('sample {}'.format(item.title), downloadFormat)\n",
    "                result.download(workspace)\n",
    "                # Delete the item after it downloads to save on space\n",
    "                result.delete()\n",
    "    except Exception as e:\n",
    "        print(\"Failed To Export File\" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e255d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function to work through the Defined Fields checking for Null values if Null populate with the defiend ifNullField.<br>  -Not Being Used\n",
    "#Input Parameters:\n",
    "#'inDf' - data frame being evaluated\n",
    "#'inField' - field being checked if Null \n",
    "#'ifNullField - field to populate 'inField' when 'inField' if null\n",
    "\n",
    "######Function Not Being Used - KRS 20220525\n",
    "\n",
    "def replaceNullField(inDf, inField, ifNullField):\n",
    "    try:\n",
    "        \n",
    "        #df['Crew'] = df.apply(lambda row: row['Specify other.'] if pd.isnull(row['Crew']) else row['Crew'], axis=1)\n",
    "        inDf[inField] = df.apply(lambda row: row[ifNullField] if pd.isnull(row[inField]) else row[inField], axis=1)\n",
    "        \n",
    "        return \"Success Function\", inDf\n",
    "        \n",
    "    except:\n",
    "\n",
    "        messageTime = timeFun()\n",
    "        print(\"Error on 'replaceNullOtherField' Function \")\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return \"Failed function - 'replaceNullOtherField'\"    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run function for 'SiteName' and 'Specify other..1' field  - Not Being Used\n",
    "# outVal = replaceNullOtherField(df,\"SiteName\", \"Specify other..1\" )\n",
    "# if outVal[0].lower() != \"success function\":\n",
    "#     print (\"WARNING - Function 'replaceNullOtherField' - Failed for 'SiteName' field - Exiting Script\")\n",
    "# else:\n",
    "\n",
    "#     print (\"Success - Function 'replaceNullOtherField'\")\n",
    "#     #Assign the df to the processed df\n",
    "#     df = outVal[1]    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
